{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d3c722d",
   "metadata": {},
   "source": [
    "# 수업을 시작하기 전\n",
    "\n",
    "딥러닝을 이해하기 위해, 기본적으로 CS231n 강의는 모두 들어야 합니다. RNN에 대한 강의는 10강을 참고하세요. \n",
    "\n",
    "[CS231n](http://cs231n.stanford.edu/)\n",
    "\n",
    "![RNN 구조 그림](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FMYzgN%2FbtqA3fa5uyw%2FAAAAAAAAAAAAAAAAAAAAACP86IyZtfIMCKp7z5CBtiLA_XZyxO_X786tVSAWfq8U%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1756652399%26allow_ip%3D%26allow_referer%3D%26signature%3D1oxykxG%252FRaTJvnkG4EWJmU6xuxo%253D)\n",
    "\n",
    "## 0. 무엇을 배우나\n",
    "\n",
    "크게 아래의 세 파트로 나누어 진행을 합니다. \n",
    "  - 첫째. 문자-단위 RNN으로 이름 분류하기\n",
    "  - 둘째. 문자-단위 RNN으로 이름 생성하기\n",
    "  - 셋째. Sequence to Sequence 네트워크와 Attention을 이용한 번역\n",
    "\n",
    "**문자-단위 RNN으로 이름 분류하기**에서는 단어를 분류하기 위해 기초적인 문자-단위의 순환 신경망(RNN)을 구축하고 학습할 거예요. RNN을 사용하여 주어진 이름이 어떠한 언어인지를 분류합니다. \n",
    "\n",
    "**문자-단위 RNN으로 이름 생성하기**에서는 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3cd24",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3440e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 18 ['Irish', 'Scottish', 'German', 'English', 'Polish', 'Arabic', 'Vietnamese', 'Japanese', 'Spanish', 'Chinese', 'Russian', 'Czech', 'Greek', 'French', 'Italian', 'Portuguese', 'Dutch', 'Korean']\n",
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters = len(all_letters) + 1 # EOS(end of sentence) 기호 추가\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "# 유니코드 문자열을 ASCII로 변환, https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# 파일을 읽고 줄 단위로 분리\n",
    "def readLines(filename):\n",
    "    with open(filename, encoding='utf-8') as some_file:\n",
    "        return [unicodeToAscii(line.strip()) for line in some_file]\n",
    "\n",
    "# 각 언어의 이름 목록인 category_lines 사전 생성\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "if n_categories == 0:\n",
    "    raise RuntimeError('Data not found. Make sure that you downloaded data '\n",
    "        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n",
    "        'the current directory.')\n",
    "\n",
    "print('# categories:', n_categories, all_categories)\n",
    "print(unicodeToAscii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d08b62",
   "metadata": {},
   "source": [
    "## 2. 네트워크 \n",
    "이 네트워크는 지난 튜토리얼의 RNN 이 다른 입력들과 연결되는 category tensor를 추가 인자로 가지게 확장합니다. category tensor는 문자 입력과 마찬가지로 one-hot 벡터입니다.\n",
    "\n",
    "역자주: 기존 입력과 category tensor를 결합하여 입력으로 사용하기 때문에 입력의 사이즈가 n_categories 만큼 커집니다.\n",
    "\n",
    "우리는 출력을 다음 문자의 확률로 해석합니다. 샘플링 할 때, 가장 확률이 높은 문자가 다음 입력 문자로 사용됩니다.\n",
    "\n",
    "더 나은 동작을 위해 두 번째 선형 레이어 o2o (은닉과 출력을 결합한 후) 를 추가했습니다 . 또한 Drop-out 계층이 있습니다. 이 계층은 주어진 확률(여기서는 0.1)로 무작위로 입력을 0 # 으로 만듭니다. 일반적으로 입력을 흐리게 해서 과적합을 막는 데 사용됩니다. 여기서 우리는 고의로 일부 혼돈을 추가하고 샘플링 다양성을 높이기 위해 네트워크의 마지막에 이것을 사용합니다.\n",
    "\n",
    "![RNN 구조 그림](https://i.imgur.com/jzVrf7f.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7cc84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32685e8c",
   "metadata": {},
   "source": [
    "## 3. 학습\n",
    "\n",
    "### 3.1. 학습 준비\n",
    "\n",
    "제일 먼저 (category, line)의 무작위 쌍을 얻는 함수:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b721752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 목록에서 무작위 아이템 반환\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "# 임의의 category 및 그 category에서 무작위 줄(이름) 얻기\n",
    "def randomTrainingPair():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    return category, line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0d065",
   "metadata": {},
   "source": [
    "각 시간 단계 마다 (즉, 학습 단어의 각 문자 마다) 네트워크의 입력은 (언어, 현재 문자, 은닉 상태) 가 되고, 출력은 (다음 문자, 다음 은닉 상태) 가 된다. 따라서 각 학습 세트 마다 언어, 입력 문자의 세트, 출력/목표 문자의 세트가 필요하다.\n",
    "\n",
    "각 시간 단계마다 현재 문자에서 다음 문자를 예측하기 때문에, 문자 쌍은 한 줄(하나의 이름)에서 연속된 문자 그룹입니다. - 예를 들어 \"ABCD<EOS>\" 는 (《A》, 《B》), (《B》, 《C》), (《C》, 《D》), (《D》, 《EOS》) 로 생성합니다.\n",
    "\n",
    "![RNN 세부 구조](https://i.imgur.com/JH58tXY.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3956bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category를 위한 One-hot 벡터\n",
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "# 입력을 위한 처음부터 마지막 문자(EOS 제외)까지의  One-hot 행렬\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# 목표를 위한 두번째 문자 부터 마지막(EOS)까지의 ``LongTensor``\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb8f1ed",
   "metadata": {},
   "source": [
    "Category(언어) Tensor는 <1 x n_categories> 크기의 One-hot Tensor 입니다. 학습시에 모든 시간 단계에서 네트워크에 이것을 전달합니다. - 이것은 설계 선택사항으로, 초기 은닉 상태 또는 또 다른 전략의 부분으로 포함될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6857d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 Category에서 Category, Input, Target Tensor를 만듭니다.\n",
    "def randomTrainingExample():\n",
    "    category, line = randomTrainingPair()\n",
    "    category_tensor = categoryTensor(category)\n",
    "    input_line_tensor = inputTensor(line)\n",
    "    target_line_tensor = targetTensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a382c",
   "metadata": {},
   "source": [
    "### 3.2. 네트워크 학습\n",
    "\n",
    "마지막 출력만 사용하는 분류와 달리, 모든 단계에서 예측을 수행하므로 모든 단계에서 손실을 계산합니다.\n",
    "\n",
    "Autograd의 마법이 각 단계의 손실들을 간단하게 합하고 마지막에 역전파를 호출하게 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d344cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    loss = torch.Tensor([0]) # 또는 그냥 ``loss = 0`` 을 사용해도 됩니다.\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item() / input_line_tensor.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8194e",
   "metadata": {},
   "source": [
    "학습에 걸리는 시간을 추적하기 위해 사람이 읽을 수 있는 문자열을 반환하는``timeSince (timestamp)`` 함수를 추가합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb20ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ebdf1e",
   "metadata": {},
   "source": [
    "학습은 일상적인 일입니다. - 몇 번 train() 을 호출하고, 몇 분 정도 기다렸다가 print_every 마다 현재 시간과 손실을 출력하고, 나중에 도식화를 위해 plot_every 마다 all_losses 에 평균 손실을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a1e0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 18s (5000 5%) 3.1046\n",
      "0m 33s (10000 10%) 2.2822\n",
      "0m 48s (15000 15%) 2.3987\n",
      "1m 3s (20000 20%) 2.8162\n",
      "1m 19s (25000 25%) 2.7443\n",
      "1m 34s (30000 30%) 3.4618\n",
      "1m 49s (35000 35%) 1.9035\n",
      "2m 4s (40000 40%) 2.8901\n",
      "2m 19s (45000 45%) 2.5303\n",
      "2m 35s (50000 50%) 2.9060\n",
      "2m 50s (55000 55%) 2.9047\n",
      "3m 5s (60000 60%) 2.4690\n",
      "3m 20s (65000 65%) 2.3412\n",
      "3m 35s (70000 70%) 2.1067\n",
      "3m 50s (75000 75%) 1.3538\n",
      "4m 5s (80000 80%) 1.6980\n",
      "4m 20s (85000 85%) 3.2584\n",
      "4m 36s (90000 90%) 2.4915\n",
      "4m 51s (95000 95%) 2.5859\n",
      "5m 7s (100000 100%) 2.0131\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(n_letters, 128, n_letters)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # ``plot_every`` 마다 초기화\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train(*randomTrainingExample())\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83339ccc",
   "metadata": {},
   "source": [
    "### 3.3. 손실 도식화\n",
    "\n",
    "all_losses를 이용한 손실의 도식화는 네트워크의 학습 상태를 보여줍니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a814807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9f715e6f20>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7686527",
   "metadata": {},
   "source": [
    "### 3.4. 네트워크 샘플링\n",
    "\n",
    "샘플링을 위해서, 네트워크에 하나의 글자를 주고 다음 문자를 물어보고 이것을 다음 문자로 전달하는 것을 EOS 토큰까지 반복합니다.\n",
    "\n",
    "  - 입력 카테고리(언어), 시작 문자, 비어 있는 은닉 상태를 위한 Tensor를 생성하십시오\n",
    "  - 시작 문자로 output_name 문자열을 생성하십시오\n",
    "  - 최대 출력 길이까지,\n",
    "    - 현재 문자를 네트워크에 전달하십시오.\n",
    "    - 가장 높은 출력에서 다음 문자와 다음 은닉 상태를 얻으십시오\n",
    "    - 만일 문자가 EOS면, 여기서 멈추십시오\n",
    "    - 만일 일반적인 문자라면, output_name 에 추가하고 계속하십시오\n",
    "  - 마지막 이름을 반환하십시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdfa1afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rovekovev\n",
      "Uantoukov\n",
      "Shimovokov\n",
      "Grenger\n",
      "Erenger\n",
      "Roumer\n",
      "Santara\n",
      "Pareza\n",
      "Allan\n",
      "Ching\n",
      "Han\n",
      "Iun\n"
     ]
    }
   ],
   "source": [
    "max_length = 20\n",
    "\n",
    "# 카테고리와 시작 문자로부터 샘플링 하기\n",
    "def sample(category, start_letter='A'):\n",
    "    with torch.no_grad():  # 샘플링에서 히스토리를 추적할 필요 없음\n",
    "        category_tensor = categoryTensor(category)\n",
    "        input = inputTensor(start_letter)\n",
    "        hidden = rnn.initHidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = rnn(category_tensor, input[0], hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == n_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_name += letter\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# 하나의 카테고리와 여러 시작 문자들로 여러 개의 샘플 얻기\n",
    "def samples(category, start_letters='ABC'):\n",
    "    for start_letter in start_letters:\n",
    "        print(sample(category, start_letter))\n",
    "\n",
    "samples('Russian', 'RUS')\n",
    "\n",
    "samples('German', 'GER')\n",
    "\n",
    "samples('Spanish', 'SPA')\n",
    "\n",
    "samples('Chinese', 'CHI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e00d1",
   "metadata": {},
   "source": [
    "# 셋째. SEQUENCE TO SEQUENCE 네트워크와 ATTENTION을 이용한 번역\n",
    "\n",
    "NLP 모델링 작업을 위한 데이터 전처리에 사용할 자체 클래스와 함수들을 작성해보겠습니다. 이 튜토리얼을 마친 뒤에는 torchtext 가 어떻게 지금까지의 튜토리얼들에서의 전처리 과정을 다루는지를 이후 튜토리얼들에서 배울 수 있습니다.\n",
    "\n",
    "이 프로젝트에서는 신경망이 불어를 영어로 번역하도록 가르칠 예정입니다.\n",
    "\n",
    "하나의 시퀀스를 다른 시퀀스로 바꾸는 두 개의 RNN이 함께 동작하는 sequence to sequence network 의 간단하지만 강력한 아이디어가 이것(번역)을 가능하게 합니다. 인코더 네트워크는 입력 시퀀스를 벡터로 압축하고, 디코더 네트워크는 해당 벡터를 새로운 시퀀스로 펼칩니다.\n",
    "\n",
    "![seq2seq 그림](https://tutorials.pytorch.kr/_images/seq2seq.png)\n",
    "\n",
    "이 모델을 개선하기 위해 Attention Mechanism 을 사용하면 디코더가 입력 시퀀스의 특정 범위에 집중할 수 있도록 합니다.\n",
    "\n",
    "이전 튜토리얼에 있는 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 분류하기 와 기초부터 시작하는 NLP: 문자-단위 RNN으로 이름 생성하기 는 각각 인코더, 디코더 모델과 비슷한 컨센을 가지기 때문에 도움이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60d60c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요구사항\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941a29c4",
   "metadata": {},
   "source": [
    "## 1. 준비\n",
    "\n",
    "문자 단위 RNN 튜토리얼에서 사용된 문자 인코딩과 유사하게, 언어의 각 단어들을 One-Hot 벡터 또는 그 단어의 주소에만 단 하나의 1을 제외하고 모두 0인 큰 벡터로 표현합니다. 한 가지 언어에 있는 수십 개의 문자와 달리 번역에는 아주 많은 단어들이 있기 때문에 인코딩 벡터는 매우 더 큽니다. 그러나 우리는 약간의 트릭를 써서 언어 당 수천 단어 만 사용하도록 데이터를 다듬을 것입니다.\n",
    "\n",
    "![word encoding 그림](https://tutorials.pytorch.kr/_images/word-encoding.png)\n",
    "\n",
    "나중에 네트워크의 입력 및 목표로 사용하려면 단어 당 고유 번호가 필요합니다. 이 모든 것을 추적하기 위해 우리는 단어→색인(word2index)과 색인→단어(index2word) 사전, 그리고 나중에 희귀 단어를 대체하는데 사용할 각 단어의 빈도 word2count 를 가진 Lang 이라는 헬퍼 클래스를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0056d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # SOS 와 EOS 포함\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea57f3",
   "metadata": {},
   "source": [
    "파일은 모두 유니 코드로 되어있어 간단하게 하기 위해 유니 코드 문자를 ASCII로 변환하고, 모든 문자를 소문자로 만들고, 대부분의 구두점을 지워줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0be85bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유니 코드 문자열을 일반 ASCII로 변환하십시오.\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# 소문자, 다듬기, 그리고 문자가 아닌 문자 제거\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70769f38",
   "metadata": {},
   "source": [
    "데이터 파일을 읽기 위해, 먼저 파일을 줄 단위로 나눈 다음 각 줄을 쌍(pair)으로 나눕니다. 이 파일들은 모두 영어 → 다른 언어 형식이기 때문에, 만약 다른 언어 → 영어로 번역하고 싶다면, 쌍을 뒤집도록 reverse 플래그를 추가했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c054532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # 파일을 읽고 줄로 분리\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # 모든 줄을 쌍으로 분리하고 정규화\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # 쌍을 뒤집고, Lang 인스턴스 생성\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29f755",
   "metadata": {},
   "source": [
    "많은 예제 문장이 있고 신속하게 학습하기를 원하기 때문에 비교적 짧고 간단한 문장으로만 데이터 셋을 정리할 것입니다. 여기서 최대 길이는 10 단어 (종료 문장 부호 포함)이며 《I am》 또는 《He is》 등의 형태로 번역되는 문장으로 필터링됩니다.(이전에 아포스트로피는 대체 됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d84f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a1ebe",
   "metadata": {},
   "source": [
    "데이터 준비를 위한 전체 과정:\n",
    "\n",
    "  - 텍스트 파일을 읽고 줄로 분리하고, 줄을 쌍으로 분리합니다.\n",
    "  - 텍스트를 정규화 하고 길이와 내용으로 필터링 합니다.\n",
    "  - 쌍을 이룬 문장들로 단어 리스트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9d4d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4601\n",
      "eng 2991\n",
      "['je ne suis pas celui qui devrait y aller', 'i m not the one who should go']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8002454",
   "metadata": {},
   "source": [
    "## 2. Seq2Seq 모델\n",
    "Recurrent Neural Network(RNN)는 시퀀스에서 작동하고 다음 단계의 입력으로 자신의 출력을 사용하는 네트워크입니다.\n",
    "\n",
    "Sequence to Sequence network, 또는 Seq2Seq 네트워크, 또는 Encoder Decoder network 는 인코더 및 디코더라고 하는 두 개의 RNN으로 구성된 모델입니다. 인코더는 입력 시퀀스를 읽고 단일 벡터를 출력하고, 디코더는 해당 벡터를 읽어 출력 시퀀스를 생성합니다.\n",
    "\n",
    "![seq2seq 그림](https://tutorials.pytorch.kr/_images/seq2seq.png)\n",
    "\n",
    "모든 입력에 해당하는 출력이 있는 단일 RNN의 시퀀스 예측과 달리 Seq2Seq 모델은 시퀀스 길이와 순서를 자유롭게하기 때문에 두 언어 사이의 번역에 이상적입니다.\n",
    "\n",
    "다음 문장 Je ne suis pas le chat noir → I am not the black cat 를 살펴 봅시다. 입력 문장의 단어 대부분은 출력 문장에서 직역(chat noir 와 black cat)되지만 약간 다른 순서도 있습니다. ne/pas 구조로 인해 입력 문장에 단어가 하나 더 있습니다. 입력 단어의 시퀀스를 직역해서 정확한 번역을 만드는 것은 어려울 것입니다.\n",
    "\n",
    "Seq2Seq 모델을 사용하면 인코더는 하나의 벡터를 생성합니다. 이상적인 경우에 입력 시퀀스의 《의미》를 문장의 N 차원 공간에 있는 단일 지점인 단일 벡터으로 인코딩합니다.\n",
    "\n",
    "### 2.1. 인코더\n",
    "\n",
    "Seq2Seq 네트워크의 인코더는 입력 문장의 모든 단어에 대해 어떤 값을 출력하는 RNN입니다. 모든 입력 단어에 대해 인코더는 벡터와 은닉 상태를 출력하고 다음 입력 단어를 위해 그 은닉 상태를 사용합니다.\n",
    "\n",
    "![encoder network 그림](https://tutorials.pytorch.kr/_images/encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0e5080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a30be04",
   "metadata": {},
   "source": [
    "### 2.2. 디코더\n",
    "\n",
    "디코더는 인코더 출력 벡터를 받아서 번역을 생성하기 위한 단어 시퀀스를 출력합니다.\n",
    "\n",
    "간단한 디코더\n",
    "\n",
    "가장 간단한 Seq2Seq 디코더는 인코더의 마지막 출력만을 이용합니다. 이 마지막 출력은 전체 시퀀스에서 문맥을 인코드하기 때문에 문맥 벡터(context vector) 로 불립니다. 이 문맥 벡터는 디코더의 초기 은닉 상태로 사용 됩니다.\n",
    "\n",
    "디코딩의 매 단계에서 디코더에게 입력 토큰과 은닉 상태가 주어집니다. 초기 입력 토큰은 문자열-시작 (start-of-string) <SOS> 토큰이고, 첫 은닉 상태는 문맥 벡터(인코더의 마지막 은닉 상태) 입니다.\n",
    "\n",
    "![decoder network 그림](https://tutorials.pytorch.kr/_images/decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bb1dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing 포함: 목표를 다음 입력으로 전달\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Teacher forcing 미포함: 자신의 예측을 다음 입력으로 사용\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # 입력으로 사용할 부분을 히스토리에서 분리\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None   # 학습 루프의 일관성 유지를 위해 `None` 을 추가로 반환\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10ea8a",
   "metadata": {},
   "source": [
    "이 모델의 결과를 학습하고 관찰하는 것을 권장하지만, 공간을 절약하기 위해 최종 목적지로 바로 이동해서 Attention 메커니즘을 소개 할 것입니다.\n",
    "\n",
    "### 2.3. Attention 디코더\n",
    "\n",
    "문맥 벡터만 인코더와 디코더 사이로 전달 된다면, 단일 벡터가 전체 문장을 인코딩 해야하는 부담을 가지게 됩니다.\n",
    "\n",
    "Attention은 디코더 네트워크가 자기 출력의 모든 단계에서 인코더 출력의 다른 부분에 《집중》 할 수 있게 합니다. 첫째 Attention 가중치 의 세트를 계산합니다. 이것은 가중치 조합을 만들기 위해서 인코더 출력 벡터와 곱해집니다. 그 결과(코드에서 attn_applied)는 입력 시퀀스의 특정 부분에 관한 정보를 포함해야하고 따라서 디코더가 알맞은 출력 단어를 선택하는 것을 도와줍니다.\n",
    "\n",
    "![Imgur 스크린샷](https://i.imgur.com/1152PYf.png)\n",
    "\n",
    "어텐션 가중치 계산은 디코더의 입력 및 은닉 상태를 입력으로 사용하는 다른 feed-forwad 계층인 attn 으로 수행됩니다. 학습 데이터에는 모든 크기의 문장이 있기 때문에 이 계층을 실제로 만들고 학습시키려면 적용 할 수 있는 최대 문장 길이 (인코더 출력을 위한 입력 길이)를 선택해야 합니다. 최대 길이의 문장은 모든 Attention 가중치를 사용하지만 더 짧은 문장은 처음 몇 개만 사용합니다.\n",
    "\n",
    "![attention decoder network 그림](https://tutorials.pytorch.kr/_images/attention-decoder-network.png)\n",
    "\n",
    "부가적 어텐션(Additive Attention)이라고도 알려진 바다나우 어텐션(Bahdanau Attention)은 기계 번역 작업과 같은 시퀀스-투-시퀀스 모델에서 일반적으로 사용하는 어텐션 기법(mechanism)입니다. 이 어텐션 기법은 Bahdanau et al.의 논문인 Neural Machine Translation by Jointly Learning to Align and Translate 에서 소개되었습니다. 이 어텐션 기법은 학습된 정렬 모델(learned alignment model)을 사용하여 인코더와 디코더의 은닉 상태(hidden state) 간의 어텐션 점수를 계산합니다. 이는 정렬된 어텐션 점수를 계산하기 위해 feed-forward 신경망을 사용합니다.\n",
    "\n",
    "또는, 디코더의 은닉 상태와 인코더의 은닉 상태 사이의 어텐션 점수를 Dot-Product로 계산하는 루옹 어텐션(Luong Attention)과 같은 다른 어텐션 기법들을 사용할 수도 있습니다. 이는 바다나우 어텐션(Bahdanau Attention)에서 사용하는 비선형 변환(non-linear transformation)을 사용하지는 않습니다.\n",
    "\n",
    "이 튜토리얼에서는 바다나우 어텐션(Bahdanau Attention)을 사용할 것입니다. 하지만 이를 루옹 어텐션(Luong Attention) 기법으로 변경해보는 것도 좋은 연습이 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1435ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing 포함: 목표를 다음 입력으로 전달\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Teacher forcing 미포함: 자신의 예측을 다음 입력으로 사용\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # 입력으로 사용할 부분을 히스토리에서 분리\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dbd084",
   "metadata": {},
   "source": [
    "## 3. 학습\n",
    "\n",
    "### 3.1. 학습 데이터 준비\n",
    "\n",
    "학습을 위해서, 각 쌍마다 입력 Tensor(입력 문장의 단어 주소)와 목표 Tensor(목표 문장의 단어 주소)가 필요합니다. 이 벡터들을 생성하는 동안 두 시퀀스에 EOS 토큰을 추가 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2870d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855805fd",
   "metadata": {},
   "source": [
    "### 3.2. 모델 학습\n",
    "\n",
    "학습을 위해서 인코더에 입력 문장을 넣고 모든 출력과 최신 은닉 상태를 추적합니다. 그런 다음 디코더에 첫 번째 입력으로 <SOS> 토큰과 인코더의 마지막 은닉 상태가 첫 번째 은닉 상태로 제공됩니다.\n",
    "\n",
    "《Teacher forcing》은 다음 입력으로 디코더의 예측을 사용하는 대신 실제 목표 출력을 다음 입력으로 사용하는 컨셉입니다. 《Teacher forcing》을 사용하면 수렴이 빨리되지만 학습된 네트워크가 잘못 사용될 때 불안정성을 보입니다..\n",
    "\n",
    "Teacher-forced 네트워크의 출력이 일관된 문법으로 읽지만 정확한 번역과는 거리가 멀다는 것을 볼 수 있습니다. 직관적으로 출력 문법을 표현하는 법을 배우고 교사가 처음 몇 단어를 말하면 의미를 《선택》 할 수 있지만, 번역에서 처음으로 문장을 만드는 법은 잘 배우지 못합니다.\n",
    "\n",
    "PyTorch의 autograd 가 제공하는 자유 덕분에 간단한 If 문으로 Teacher Forcing을 사용할지 아니면 사용하지 않을지를 선택할 수 있습니다. 더 많이 사용하려면 teacher_forcing_ratio 를 확인하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5871ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f67406",
   "metadata": {},
   "source": [
    "이것은 현재 시간과 진행률%을 고려해 경과된 시간과 남은 예상 시간을 출력하는 헬퍼 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2930b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e85d29",
   "metadata": {},
   "source": [
    "전체 학습 과정은 다음과 같습니다:\n",
    "\n",
    "  - 타이머 시작\n",
    "  - optimizers와 criterion 초기화\n",
    "  - 학습 쌍의 세트 생성\n",
    "  - 도식화를 위한 빈 손실 배열 시작\n",
    "그런 다음 우리는 여러 번 train 을 호출하며 때로는 진행률 (예제의 %, 현재까지의 예상 시간)과 평균 손실을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0ab21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3264b75f",
   "metadata": {},
   "source": [
    "### 3.3. 결과 도식화\n",
    "\n",
    "matplotlib로 학습 중에 저장된 손실 값 plot_losses 의 배열을 사용하여 도식화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9ddcb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # 주기적인 간격으로 이 locator가 tick을 설정\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8abfecc",
   "metadata": {},
   "source": [
    "### 3.4. 평가\n",
    "\n",
    "평가는 대부분 학습과 동일하지만 목표가 없으므로 각 단계마다 디코더의 예측을 되돌려 전달합니다. 단어를 예측할 때마다 그 단어를 출력 문자열에 추가합니다. 만약 EOS 토큰을 예측하면 거기에서 멈춥니다. 나중에 도식화를 위해서 디코더의 Attention 출력을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d9ff382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdec9c0",
   "metadata": {},
   "source": [
    "학습 세트에 있는 임의의 문장으로 평가한 다음, 입력(input), 목표(target) 및 출력(output) 값들을 표시하여 주관적으로 품질에 대해 판단해볼 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71280969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd0df14",
   "metadata": {},
   "source": [
    "### 3.5. 학습과 평가\n",
    "\n",
    "이러한 모든 헬퍼 함수를 이용해서 (추가 작업처럼 보이지만 여러 실험을 더 쉽게 수행 할 수 있음) 실제로 네트워크를 초기화하고 학습을 시작할 수 있습니다.\n",
    "\n",
    "입력 문장이 많이 필터링되었음을 기억하십시오. 이 작은 데이터 세트의 경우 256 크기의 은닉 노드(hidden node)와 단일 GRU 계층 같은 상대적으로 작은 네트워크를 사용할 수 있습니다. MacBook CPU에서 약 40분 후에 합리적인 결과를 얻을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d696634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11445 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4601\n",
      "eng 2991\n",
      "1m 9s (- 17m 28s) (5 6%) 1.5437\n",
      "2m 20s (- 16m 25s) (10 12%) 0.6817\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e251e427",
   "metadata": {},
   "source": [
    "드롭아웃(dropout) 레이어들을 평가 (eval) 모드로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10997061",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6e123",
   "metadata": {},
   "source": [
    "### 3.6. Attention 시각화\n",
    "\n",
    "Attention 메커니즘의 유용한 속성은 하나는 해석 가능성이 높은 출력입니다. 입력 시퀀스의 특정 인코더 출력에 가중치를 부여하는 데 사용되므로 각 시간 단계에서 네트워크가 가장 집중되는 위치를 파악할 수 있습니다.\n",
    "\n",
    "Attention 출력을 행렬로 표시하기 위해서는 plt.matshow(attentions) 을 그냥 실행해도 됩니다. 하지만 좀 더 나은 시각화를 위해 축(axis)과 라벨(label)을 추가하는 약간의 작업을 더 해보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e62c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # 축 설정\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # 매 틱마다 라벨 보여주기\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
    "\n",
    "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
    "\n",
    "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
    "\n",
    "evaluateAndShowAttention('je suis reellement fiere de vous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec3a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
